Starting... 
2021-04-11 23:26:02.425275: Using splits from existing split file: /home/andyding/Desktop/jsad-tbone/01_ading/nnUnet/nnUNet_preprocessed/Task101_TemporalBone/splits_final.pkl 
2021-04-11 23:26:02.450687: The split file contains 5 splits. 
2021-04-11 23:26:02.450728: Desired fold for training: 0 
2021-04-11 23:26:02.450756: This split has 92 training and 23 validation cases. 
2021-04-11 23:26:02.573641: TRAINING KEYS:
 odict_keys(['jhu_000', 'jhu_001', 'jhu_002', 'jhu_003', 'jhu_005', 'jhu_006', 'jhu_007', 'jhu_008', 'jhu_010', 'jhu_011', 'jhu_012', 'jhu_013', 'jhu_014', 'jhu_015', 'jhu_017', 'jhu_018', 'jhu_020', 'jhu_021', 'jhu_022', 'jhu_023', 'jhu_025', 'jhu_026', 'jhu_027', 'jhu_028', 'jhu_029', 'jhu_030', 'jhu_031', 'jhu_032', 'jhu_033', 'jhu_034', 'jhu_035', 'jhu_036', 'jhu_037', 'jhu_038', 'jhu_039', 'jhu_041', 'jhu_043', 'jhu_044', 'jhu_045', 'jhu_046', 'jhu_047', 'jhu_050', 'jhu_052', 'jhu_053', 'jhu_055', 'jhu_056', 'jhu_057', 'jhu_059', 'jhu_060', 'jhu_061', 'jhu_062', 'jhu_064', 'jhu_066', 'jhu_067', 'jhu_070', 'jhu_071', 'jhu_072', 'jhu_073', 'jhu_074', 'jhu_075', 'jhu_076', 'jhu_077', 'jhu_078', 'jhu_079', 'jhu_080', 'jhu_081', 'jhu_082', 'jhu_083', 'jhu_084', 'jhu_088', 'jhu_089', 'jhu_091', 'jhu_092', 'jhu_093', 'jhu_094', 'jhu_095', 'jhu_098', 'jhu_099', 'jhu_100', 'jhu_101', 'jhu_102', 'jhu_103', 'jhu_104', 'jhu_105', 'jhu_106', 'jhu_107', 'jhu_109', 'jhu_110', 'jhu_111', 'jhu_112', 'jhu_113', 'jhu_114']) 
2021-04-11 23:26:02.573725: VALIDATION KEYS:
 odict_keys(['jhu_004', 'jhu_009', 'jhu_016', 'jhu_019', 'jhu_024', 'jhu_040', 'jhu_042', 'jhu_048', 'jhu_049', 'jhu_051', 'jhu_054', 'jhu_058', 'jhu_063', 'jhu_065', 'jhu_068', 'jhu_069', 'jhu_085', 'jhu_086', 'jhu_087', 'jhu_090', 'jhu_096', 'jhu_097', 'jhu_108']) 
2021-04-11 23:26:04.242303: lr: 0.01 
2021-04-11 23:29:08.683962: Unable to plot network architecture: 
2021-04-11 23:29:08.691949: No module named 'hiddenlayer' 
2021-04-11 23:29:08.692007: 
printing the network instead:
 
2021-04-11 23:29:08.692048: Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=[2, 2, 2], stride=[2, 2, 2], bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=[2, 2, 2], stride=[2, 2, 2], bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=[2, 2, 2], stride=[2, 2, 2], bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=[2, 2, 2], stride=[2, 2, 2], bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=[2, 2, 2], stride=[2, 2, 2], bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 17, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 17, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 17, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 17, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 17, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
) 
2021-04-11 23:29:08.694286: 
 
2021-04-11 23:29:08.694494: 
epoch:  0 
2021-04-12 00:31:08.155595: train loss : 1.0721 
2021-04-12 00:38:31.723085: validation loss: 0.8443 
2021-04-12 00:38:32.293379: Average global foreground Dice: [0.8971241552671837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] 
2021-04-12 00:38:32.293718: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-12 00:39:26.296521: lr: 0.00997 
2021-04-12 00:39:26.430183: This epoch took 4217.732547 s
 
2021-04-12 00:39:26.430439: 
epoch:  1 
2021-04-12 01:29:51.378577: train loss : 0.8060 
2021-04-12 01:37:17.694072: validation loss: 0.6638 
2021-04-12 01:37:19.775635: Average global foreground Dice: [0.8948142038843213, 0.0, 0.0, 0.0, 0.31723649013938837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1399934184849675, 0.0, 0.0, 0.0] 
2021-04-12 01:37:19.776039: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-12 01:37:38.484948: lr: 0.00994 
2021-04-12 01:37:38.560135: saving checkpoint... 
2021-04-12 01:37:46.289358: done, saving took 7.80 seconds 
2021-04-12 01:37:47.835025: This epoch took 3501.404363 s
 
2021-04-12 01:37:47.835306: 
epoch:  2 
2021-04-12 02:29:05.362629: train loss : 0.7247 
2021-04-12 02:37:15.576156: validation loss: 0.6598 
2021-04-12 02:37:17.790596: Average global foreground Dice: [0.927162888879505, 0.0, 0.0, 0.0, 0.5555661199797475, 0.018891034750357784, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13574931558652745, 0.0, 0.0, 0.0] 
2021-04-12 02:37:17.790936: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-12 02:37:38.933641: lr: 0.00991 
2021-04-12 02:37:39.008494: saving checkpoint... 
2021-04-12 02:38:17.271858: done, saving took 38.34 seconds 
2021-04-12 02:38:19.281585: This epoch took 3631.446103 s
 
2021-04-12 02:38:19.281664: 
epoch:  3 
2021-04-12 03:28:47.755137: train loss : 0.6514 
2021-04-12 03:35:06.302849: validation loss: 0.7085 
2021-04-12 03:35:08.407189: Average global foreground Dice: [0.8702414223669233, 0.0, 0.0, 0.0, 0.6271718331419824, 0.342844686520652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018966359517116504, 0.0, 0.08341219918453019, 0.0] 
2021-04-12 03:35:08.407522: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-12 03:35:20.953886: lr: 0.00988 
2021-04-12 03:35:20.984249: saving checkpoint... 
2021-04-12 03:35:37.018558: done, saving took 16.06 seconds 
2021-04-12 03:35:37.274937: This epoch took 3437.993187 s
 
2021-04-12 03:35:37.275210: 
epoch:  4 
2021-04-12 04:25:21.967746: train loss : 0.6660 
2021-04-12 04:33:26.177098: validation loss: 0.5683 
2021-04-12 04:33:27.339623: Average global foreground Dice: [0.9091126458844461, 0.0, 0.0, 0.0, 0.7322370273168487, 0.35927989755063505, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.46757635585452595, 0.0, 0.0, 0.008361520986952682] 
2021-04-12 04:33:27.340261: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-12 04:33:43.078170: lr: 0.00985 
2021-04-12 04:33:43.119829: saving checkpoint... 
2021-04-12 04:33:53.044058: done, saving took 9.97 seconds 
2021-04-12 04:33:54.577682: This epoch took 3497.301945 s
 
2021-04-12 04:33:54.577777: 
epoch:  5 
2021-04-12 05:21:48.113322: train loss : 0.5390 
2021-04-12 05:30:31.435501: validation loss: 0.5291 
2021-04-12 05:30:31.909731: Average global foreground Dice: [0.9264081295772334, 0.0, 0.0, 0.0, 0.810450079994787, 0.41379994646604823, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4573797044395488, 0.0, 0.010797822074024022, 0.22959983448368415] 
2021-04-12 05:30:31.910048: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-12 05:30:46.965285: lr: 0.00982 
2021-04-12 05:30:46.998425: saving checkpoint... 
2021-04-12 05:31:08.357636: done, saving took 21.39 seconds 
2021-04-12 05:31:10.268413: This epoch took 3435.690582 s
 
2021-04-12 05:31:10.268739: 
epoch:  6 
2021-04-12 06:21:43.340801: train loss : 0.5385 
2021-04-12 06:29:49.590484: validation loss: 0.5398 
2021-04-12 06:29:53.143745: Average global foreground Dice: [0.9125539981699277, 0.0, 0.0, 0.0, 0.7779996442485899, 0.4482911161680557, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4424628963967598, 0.0, 0.014805480741935707, 0.433170263666605] 
2021-04-12 06:29:53.144317: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-12 06:30:08.709239: lr: 0.00979 
2021-04-12 06:30:08.747258: saving checkpoint... 
2021-04-12 06:31:07.766279: done, saving took 59.06 seconds 
2021-04-12 06:31:08.358363: This epoch took 3598.089413 s
 
2021-04-12 06:31:08.358451: 
epoch:  7 
2021-04-12 07:18:00.502239: train loss : 0.4868 
2021-04-12 07:24:55.551638: validation loss: 0.4641 
2021-04-12 07:24:55.854573: Average global foreground Dice: [0.9379591301256448, 0.0, 0.0, 0.0, 0.819728233764247, 0.5113890992759808, 0.0, 0.0, 0.0, 0.03999161812606763, 0.0, 0.0, 0.5323906997847786, 0.0, 0.0, 0.5303297401736997] 
2021-04-12 07:24:55.855072: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-12 07:25:16.570597: lr: 0.00976 
2021-04-12 07:25:16.616271: saving checkpoint... 
2021-04-12 07:25:34.699456: done, saving took 18.13 seconds 
2021-04-12 07:25:36.231205: This epoch took 3267.872698 s
 
2021-04-12 07:25:36.231269: 
epoch:  8 
2021-04-12 08:16:27.446333: train loss : 0.4740 
2021-04-12 08:23:24.711535: validation loss: 0.4019 
2021-04-12 08:23:25.288211: Average global foreground Dice: [0.9163316267035713, 0.0, 0.0, 0.0, 0.848479088488014, 0.651132987194895, 0.0, 0.0, 0.0, 0.33596477536904534, 0.0, 0.0, 0.4753410685972343, 0.0, 1.8047207886389217e-06, 0.6102840261228062] 
2021-04-12 08:23:25.288538: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-12 08:23:42.455705: lr: 0.00973 
2021-04-12 08:23:42.526159: saving checkpoint... 
2021-04-12 08:23:57.546885: done, saving took 15.09 seconds 
2021-04-12 08:23:57.791032: This epoch took 3501.559716 s
 
2021-04-12 08:23:57.791315: 
epoch:  9 
2021-04-12 09:14:00.216216: train loss : 0.4475 
2021-04-12 09:22:22.937542: validation loss: 0.3582 
2021-04-12 09:22:24.269020: Average global foreground Dice: [0.9382859114097278, 0.0, 0.0, 0.0, 0.8017325711045141, 0.6312684267000641, 0.0, 0.0, 0.0, 0.3121042270380859, 0.0, 0.1962319497582565, 0.43954139581101875, 0.0, 3.743991613458786e-05, 0.5184644000909682] 
2021-04-12 09:22:24.269410: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-12 09:22:58.625896: lr: 0.009699 
2021-04-12 09:22:58.699890: saving checkpoint... 
2021-04-12 09:23:12.516515: done, saving took 13.89 seconds 
2021-04-12 09:23:14.039910: This epoch took 3556.248415 s
 
2021-04-12 09:23:14.039978: 
epoch:  10 
2021-04-12 10:11:25.867581: train loss : 0.4148 
2021-04-12 10:18:40.352832: validation loss: 0.3505 
2021-04-12 10:18:42.838912: Average global foreground Dice: [0.9414950812291832, 0.0, 0.0, 0.0, 0.8399834207457023, 0.5894406933188097, 0.0, 0.0, 0.0, 0.4114330574238549, 0.0, 0.03828522755971674, 0.5563158737542899, 0.0, 0.0, 0.7035042166064843] 
2021-04-12 10:18:42.839310: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-12 10:19:07.254088: lr: 0.009669 
2021-04-12 10:19:07.307002: saving checkpoint... 
2021-04-12 10:19:36.318220: done, saving took 29.06 seconds 
2021-04-12 10:19:36.902467: This epoch took 3382.862433 s
 
2021-04-12 10:19:36.902791: 
epoch:  11 
2021-04-12 11:08:50.042783: train loss : 0.3905 
2021-04-12 11:16:20.015078: validation loss: 0.2749 
2021-04-12 11:16:22.271997: Average global foreground Dice: [0.9346071519183762, 0.0, 0.0, 0.0, 0.8652555064354198, 0.7007911662420044, 0.0, 0.0, 1.8819337496588995e-05, 0.6165600020369375, 0.0, 0.46740833297879936, 0.6361029702524663, 0.0, 0.00011308652045753694, 0.661693132859736] 
2021-04-12 11:16:22.272363: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-12 11:16:37.179981: lr: 0.009639 
2021-04-12 11:16:37.259760: saving checkpoint... 
2021-04-12 11:16:53.585667: done, saving took 16.41 seconds 
2021-04-12 11:16:53.974385: This epoch took 3437.071405 s
 
2021-04-12 11:16:53.974696: 
epoch:  12 
2021-04-12 12:05:28.579561: train loss : 0.3757 
2021-04-12 12:13:07.483201: validation loss: 0.3727 
2021-04-12 12:13:10.894857: Average global foreground Dice: [0.9070218829728215, 6.053012281561919e-05, 0.000738649041679811, 0.0, 0.7892263845245898, 0.501167138148323, 0.0, 0.0, 0.05134795667607172, 0.5498504340204203, 0.0, 0.3542336073545259, 0.5966397020760933, 0.0, 0.0239599003636787, 0.5688118391416863] 
2021-04-12 12:13:11.091935: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-12 12:13:33.005440: lr: 0.009609 
2021-04-12 12:13:33.052434: saving checkpoint... 
2021-04-12 12:16:11.405754: done, saving took 158.40 seconds 
2021-04-12 12:16:11.662511: This epoch took 3557.687607 s
 
2021-04-12 12:16:11.662786: 
epoch:  13 
2021-04-12 13:04:43.044168: train loss : 0.3719 
2021-04-12 13:13:06.697634: validation loss: 0.3254 
2021-04-12 13:13:07.468138: Average global foreground Dice: [0.9241450223923974, 0.42781983997246836, 0.3310156277276011, 0.0, 0.8036154749343882, 0.657725927164875, 0.0, 0.0, 0.1931433155489802, 0.6245503028536642, 0.0, 0.38419305064021236, 0.4357923480399383, 0.0, 0.0012302943125647935, 0.5835095245491995] 
2021-04-12 13:13:07.468557: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-12 13:13:18.707994: lr: 0.009579 
2021-04-12 13:13:18.740425: saving checkpoint... 
2021-04-12 13:13:52.371804: done, saving took 33.66 seconds 
2021-04-12 13:13:52.824488: This epoch took 3461.161510 s
 
2021-04-12 13:13:52.824810: 
epoch:  14 
2021-04-12 14:02:46.306925: train loss : 0.2707 
2021-04-12 14:10:42.492088: validation loss: 0.2665 
2021-04-12 14:10:44.273196: Average global foreground Dice: [0.9400409239319046, 0.49620667608719554, 0.48871412925443725, 0.0, 0.864948927143986, 0.5708023597233529, 0.0, 0.0, 0.4213506242878088, 0.7019684432069232, 0.0, 0.4789709100716439, 0.5106960318513477, 0.0, 0.0821907633559854, 0.8028139140607724] 
2021-04-12 14:10:44.273534: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-12 14:11:01.721799: lr: 0.009549 
2021-04-12 14:11:01.767935: saving checkpoint... 
2021-04-12 14:11:29.486683: done, saving took 27.76 seconds 
2021-04-12 14:11:31.240489: This epoch took 3458.415484 s
 
2021-04-12 14:11:31.240777: 
epoch:  15 
2021-04-12 15:01:03.067146: train loss : 0.3116 
2021-04-12 15:08:38.605500: validation loss: 0.1697 
2021-04-12 15:08:39.628590: Average global foreground Dice: [0.9169403890385076, 0.6112992739117472, 0.683251019823458, 0.0, 0.8742006304481076, 0.7341442410535058, 0.0, 0.0, 0.5824747078654077, 0.72075103709658, 0.0, 0.5567907484494775, 0.6311661921710399, 0.0, 0.00044785127778494536, 0.8174009642650542] 
2021-04-12 15:08:39.629079: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-12 15:08:51.410631: lr: 0.009519 
2021-04-12 15:08:51.468689: saving checkpoint... 
2021-04-12 15:09:10.241653: done, saving took 18.83 seconds 
2021-04-12 15:09:11.583747: This epoch took 3460.342790 s
 
2021-04-12 15:09:11.583956: 
epoch:  16 
