Starting... 
2021-04-30 01:31:25.863340: Using splits from existing split file: /media/jpsoong/New Volume/jsad-tbone/02_jsoong_ablation_3/nnUnet/nnUNet_preprocessed/Task305_TemporalBone/splits_final.pkl 
2021-04-30 01:31:25.864710: The split file contains 1 splits. 
2021-04-30 01:31:25.864884: Desired fold for training: 0 
2021-04-30 01:31:25.865050: This split has 120 training and 7 validation cases. 
2021-04-30 01:31:26.035409: TRAINING KEYS:
 odict_keys(['jhu_000', 'jhu_001', 'jhu_002', 'jhu_003', 'jhu_004', 'jhu_012', 'jhu_013', 'jhu_014', 'jhu_015', 'jhu_016', 'jhu_017', 'jhu_018', 'jhu_019', 'jhu_020', 'jhu_021', 'jhu_022', 'jhu_023', 'jhu_024', 'jhu_025', 'jhu_026', 'jhu_027', 'jhu_028', 'jhu_029', 'jhu_030', 'jhu_031', 'jhu_032', 'jhu_033', 'jhu_034', 'jhu_035', 'jhu_036', 'jhu_037', 'jhu_038', 'jhu_039', 'jhu_040', 'jhu_041', 'jhu_042', 'jhu_043', 'jhu_044', 'jhu_045', 'jhu_046', 'jhu_047', 'jhu_048', 'jhu_049', 'jhu_050', 'jhu_051', 'jhu_052', 'jhu_053', 'jhu_054', 'jhu_055', 'jhu_056', 'jhu_057', 'jhu_058', 'jhu_059', 'jhu_060', 'jhu_061', 'jhu_062', 'jhu_063', 'jhu_064', 'jhu_065', 'jhu_066', 'jhu_067', 'jhu_068', 'jhu_069', 'jhu_070', 'jhu_071', 'jhu_072', 'jhu_073', 'jhu_074', 'jhu_075', 'jhu_076', 'jhu_077', 'jhu_078', 'jhu_079', 'jhu_080', 'jhu_081', 'jhu_082', 'jhu_083', 'jhu_084', 'jhu_085', 'jhu_086', 'jhu_087', 'jhu_088', 'jhu_089', 'jhu_090', 'jhu_091', 'jhu_092', 'jhu_093', 'jhu_094', 'jhu_095', 'jhu_096', 'jhu_097', 'jhu_098', 'jhu_099', 'jhu_100', 'jhu_101', 'jhu_102', 'jhu_103', 'jhu_104', 'jhu_105', 'jhu_106', 'jhu_107', 'jhu_108', 'jhu_109', 'jhu_110', 'jhu_111', 'jhu_112', 'jhu_113', 'jhu_114', 'jhu_115', 'jhu_116', 'jhu_117', 'jhu_118', 'jhu_119', 'jhu_120', 'jhu_121', 'jhu_122', 'jhu_123', 'jhu_124', 'jhu_125', 'jhu_126']) 
2021-04-30 01:31:26.036064: VALIDATION KEYS:
 odict_keys(['jhu_005', 'jhu_006', 'jhu_007', 'jhu_008', 'jhu_009', 'jhu_010', 'jhu_011']) 
2021-04-30 01:31:29.968165: loading checkpoint /media/jpsoong/New Volume/jsad-tbone/02_jsoong_ablation_3/nnUnet/nnUNet_trained_models/nnUNet/3d_fullres/Task305_TemporalBone/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0/model_latest.model train= True 
2021-04-30 01:31:30.193600: lr: 0.008487 
2021-04-30 01:31:46.923297: Unable to plot network architecture: 
2021-04-30 01:31:46.963770: No module named 'hiddenlayer' 
2021-04-30 01:31:47.008913: 
printing the network instead:
 
2021-04-30 01:31:47.045851: Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=[2, 2, 2], stride=[2, 2, 2], bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=[2, 2, 2], stride=[2, 2, 2], bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=[2, 2, 2], stride=[2, 2, 2], bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=[2, 2, 2], stride=[2, 2, 2], bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=[2, 2, 2], stride=[2, 2, 2], bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 17, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 17, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 17, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 17, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 17, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
) 
2021-04-30 01:31:47.094221: 
 
2021-04-30 01:31:47.128510: 
epoch:  50 
2021-04-30 01:37:17.223463: train loss : 0.0487 
2021-04-30 01:37:42.191538: validation loss: 0.1380 
2021-04-30 01:37:42.193076: Average global foreground Dice: [0.917655918670807, 0.8453856888847107, 0.8016253516801716, 0.2713346073038631, 0.9082144085016954, 0.8801524676285568, 0.3053335988157177, 0.4946446422621031, 0.5900566737353821, 0.6818649627594182, 0.0, 0.5889508610106506, 0.6884187759827551, 0.0, 0.5579781710510396, 0.7190351078337732] 
2021-04-30 01:37:42.193591: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-30 01:37:42.710992: lr: 0.008456 
2021-04-30 01:37:42.739176: saving checkpoint... 
2021-04-30 01:37:43.792176: done, saving took 1.08 seconds 
2021-04-30 01:37:43.802308: This epoch took 356.639097 s
 
2021-04-30 01:37:43.802465: 
epoch:  51 
2021-04-30 01:43:03.498602: train loss : 0.0459 
2021-04-30 01:43:28.495259: validation loss: -0.0008 
2021-04-30 01:43:28.497332: Average global foreground Dice: [0.9390846393957566, 0.7866284886328354, 0.8232104576752777, 0.3021999675452628, 0.9338441260481959, 0.9129248270767911, 0.2785380831174168, 0.2727993805593851, 0.4834632303102222, 0.7376370324375161, 0.0, 0.7730885257268275, 0.7478719169113752, 0.0, 0.46901433799268105, 0.8129616961411986] 
2021-04-30 01:43:28.497533: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-30 01:43:28.893419: lr: 0.008426 
2021-04-30 01:43:28.922262: saving checkpoint... 
2021-04-30 01:43:29.991181: done, saving took 1.10 seconds 
2021-04-30 01:43:29.999681: This epoch took 346.197084 s
 
2021-04-30 01:43:29.999882: 
epoch:  52 
2021-04-30 01:48:50.160639: train loss : 0.0440 
2021-04-30 01:49:15.220097: validation loss: 0.0129 
2021-04-30 01:49:15.222198: Average global foreground Dice: [0.9425857283321065, 0.8472770513585858, 0.8377396649680003, 0.4468141730982775, 0.9176838238714043, 0.9240513694539302, 0.4010510470148652, 0.22131697341513293, 0.5171420961757467, 0.7611639146676973, 0.0, 0.7779971490112595, 0.7652441314915556, 0.0, 0.625296911784071, 0.7254030207989112] 
2021-04-30 01:49:15.222373: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-30 01:49:15.609338: lr: 0.008395 
2021-04-30 01:49:15.637844: saving checkpoint... 
2021-04-30 01:49:16.679814: done, saving took 1.07 seconds 
2021-04-30 01:49:16.688616: This epoch took 346.688572 s
 
2021-04-30 01:49:16.688848: 
epoch:  53 
2021-04-30 01:54:36.627645: train loss : 0.0212 
2021-04-30 01:55:01.601265: validation loss: 0.0568 
2021-04-30 01:55:01.603359: Average global foreground Dice: [0.9365340510584317, 0.8505297963477869, 0.8410847984873207, 0.46507957122448773, 0.9110466513693406, 0.8564090102387985, 0.3481462043111528, 0.2638115866531407, 0.5728223100737321, 0.7466859794196842, 0.0, 0.7435375513998601, 0.6895001406282905, 0.0, 0.593066959183701, 0.7857073903292013] 
2021-04-30 01:55:01.603544: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-30 01:55:01.983125: lr: 0.008364 
2021-04-30 01:55:02.012283: saving checkpoint... 
2021-04-30 01:55:03.062071: done, saving took 1.08 seconds 
2021-04-30 01:55:03.069368: This epoch took 346.380320 s
 
2021-04-30 01:55:03.069522: 
epoch:  54 
2021-04-30 02:00:23.166025: train loss : 0.0030 
2021-04-30 02:00:48.231898: validation loss: 0.0095 
2021-04-30 02:00:48.234020: Average global foreground Dice: [0.949860633535441, 0.8382751083025317, 0.8384326546466837, 0.4796732714704227, 0.931002947524231, 0.8556563108541672, 0.4397407286959057, 0.3163072408701459, 0.6054301641885529, 0.7596571002825125, 0.0, 0.7434641206277703, 0.714882176544972, 0.0, 0.45167419131337616, 0.710569095486037] 
2021-04-30 02:00:48.234224: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-30 02:00:48.632906: lr: 0.008334 
2021-04-30 02:00:48.663067: saving checkpoint... 
2021-04-30 02:00:49.751109: done, saving took 1.12 seconds 
2021-04-30 02:00:49.758941: This epoch took 346.689258 s
 
2021-04-30 02:00:49.759142: 
epoch:  55 
2021-04-30 02:06:09.604415: train loss : 0.0345 
2021-04-30 02:06:34.604452: validation loss: 0.1261 
2021-04-30 02:06:34.606285: Average global foreground Dice: [0.9327526540658917, 0.8401872651677444, 0.8417632662756026, 0.4070240641903815, 0.9091135392287616, 0.8599018162375852, 0.40819807350864684, 0.2707529937081388, 0.5621605674168804, 0.7444318290540767, 0.0, 0.5436978115813392, 0.6012016539282344, 0.0, 0.6106812216469445, 0.8740020109781779] 
2021-04-30 02:06:34.607603: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-30 02:06:35.003042: lr: 0.008303 
2021-04-30 02:06:35.032264: saving checkpoint... 
2021-04-30 02:06:36.123580: done, saving took 1.12 seconds 
2021-04-30 02:06:36.131075: This epoch took 346.371777 s
 
2021-04-30 02:06:36.131259: 
epoch:  56 
2021-04-30 02:11:55.849808: train loss : 0.0282 
2021-04-30 02:12:20.856310: validation loss: 0.0146 
2021-04-30 02:12:20.857895: Average global foreground Dice: [0.9481969220924904, 0.8138497239838934, 0.7927572329799824, 0.43568039844161827, 0.9299992521559257, 0.9205504713536898, 0.3073773599211464, 0.3295197259011401, 0.5642147640411004, 0.6784999133651649, 0.0, 0.6347997019997919, 0.7555420048826595, 0.0, 0.36701925676656616, 0.6765491269313313] 
2021-04-30 02:12:20.858133: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-30 02:12:21.249072: lr: 0.008272 
2021-04-30 02:12:21.249322: This epoch took 345.117918 s
 
2021-04-30 02:12:21.249516: 
epoch:  57 
2021-04-30 02:17:40.935555: train loss : 0.0180 
2021-04-30 02:18:05.983069: validation loss: -0.0044 
2021-04-30 02:18:05.985018: Average global foreground Dice: [0.9337085572782133, 0.8576945204076003, 0.8595948359268778, 0.4790028130202652, 0.9352822666014233, 0.8492101978618369, 0.4909343497310583, 0.4113796456608875, 0.5938919319662278, 0.7402840298350377, 0.0, 0.8039887711275726, 0.6989168356736848, 0.0, 0.7032879001094983, 0.8400397561777845] 
2021-04-30 02:18:05.985277: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-30 02:18:06.382123: lr: 0.008242 
2021-04-30 02:18:06.411656: saving checkpoint... 
2021-04-30 02:18:07.499646: done, saving took 1.12 seconds 
2021-04-30 02:18:07.632190: This epoch took 346.382502 s
 
2021-04-30 02:18:07.632453: 
epoch:  58 
2021-04-30 02:23:27.715280: train loss : 0.0116 
2021-04-30 02:23:52.815029: validation loss: -0.0974 
2021-04-30 02:23:52.817076: Average global foreground Dice: [0.9525916771654237, 0.8438304084804322, 0.8536044444979723, 0.5257140572844836, 0.9441781668651306, 0.9108306300423399, 0.42979638009049775, 0.2652289027074732, 0.586553640679824, 0.7570396172805968, 0.0, 0.827055885032937, 0.8236821725555304, 0.0, 0.6915529411933825, 0.8441100568408199] 
2021-04-30 02:23:52.817334: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-30 02:23:53.214801: lr: 0.008211 
2021-04-30 02:23:53.244274: saving checkpoint... 
2021-04-30 02:23:54.356479: done, saving took 1.14 seconds 
2021-04-30 02:23:54.366183: This epoch took 346.733519 s
 
2021-04-30 02:23:54.366428: 
epoch:  59 
2021-04-30 02:29:14.612905: train loss : 0.0244 
2021-04-30 02:29:39.603202: validation loss: 0.0669 
2021-04-30 02:29:39.605181: Average global foreground Dice: [0.945317228788154, 0.8669538861728194, 0.8414492302006298, 0.45464391872633253, 0.8760699608519678, 0.879264029664392, 0.45756610750902643, 0.28567195140020746, 0.5897864334417667, 0.6776339552812473, 0.0, 0.6272487641523591, 0.6952884484875756, 0.0, 0.4651909141571089, 0.8389534100102815] 
2021-04-30 02:29:39.605404: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-30 02:29:39.990977: lr: 0.008181 
2021-04-30 02:29:39.991213: This epoch took 345.624573 s
 
2021-04-30 02:29:39.991378: 
epoch:  60 
2021-04-30 02:35:00.228567: train loss : 0.0041 
2021-04-30 02:35:25.225128: validation loss: 0.0475 
2021-04-30 02:35:25.226728: Average global foreground Dice: [0.9448183715163596, 0.7475455551362656, 0.7338829171044479, 0.46550519697707404, 0.9367113057353255, 0.9322579011746907, 0.3738218390804598, 0.22130094309889203, 0.6066071701324489, 0.7071986786597073, 0.00010889094571786355, 0.7650416368346128, 0.7080499870962237, 0.0, 0.4389709789561522, 0.8304267785038886] 
2021-04-30 02:35:25.226943: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-30 02:35:25.718634: lr: 0.00815 
2021-04-30 02:35:25.718945: This epoch took 345.727408 s
 
2021-04-30 02:35:25.719167: 
epoch:  61 
2021-04-30 02:40:46.276247: train loss : 0.0030 
2021-04-30 02:41:11.374683: validation loss: 0.0171 
2021-04-30 02:41:11.376744: Average global foreground Dice: [0.9290194178494875, 0.8663158325346548, 0.8582546758867333, 0.5132994709274292, 0.938559343164119, 0.8952033777471633, 0.5078168424184065, 0.30598071943343835, 0.6110328434356611, 0.668186601192564, 0.0, 0.714806478987566, 0.7158772211403869, 0.0, 0.47305717456563434, 0.7841950906724672] 
2021-04-30 02:41:11.376960: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-30 02:41:11.765685: lr: 0.008119 
2021-04-30 02:41:11.794555: saving checkpoint... 
2021-04-30 02:41:12.813743: done, saving took 1.05 seconds 
2021-04-30 02:41:12.823797: This epoch took 347.104412 s
 
2021-04-30 02:41:12.823998: 
epoch:  62 
2021-04-30 02:46:33.471339: train loss : -0.0247 
2021-04-30 02:46:58.491463: validation loss: -0.0015 
2021-04-30 02:46:58.493641: Average global foreground Dice: [0.9364365238178375, 0.8325148119066315, 0.8549846282790363, 0.5149882323795367, 0.9391442965833295, 0.9179115871668524, 0.44005011209283923, 0.3715829582719295, 0.5236944161723932, 0.6664732448835662, 0.020151760169175272, 0.8591188612792269, 0.732019097701801, 0.0, 0.5425495371392718, 0.8223401585610126] 
2021-04-30 02:46:58.493860: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-30 02:46:58.893365: lr: 0.008088 
2021-04-30 02:46:58.922737: saving checkpoint... 
2021-04-30 02:47:00.008588: done, saving took 1.11 seconds 
2021-04-30 02:47:00.019813: This epoch took 347.195646 s
 
2021-04-30 02:47:00.020014: 
epoch:  63 
2021-04-30 02:52:20.547457: train loss : 0.0417 
2021-04-30 02:52:45.667517: validation loss: -0.0385 
2021-04-30 02:52:45.669835: Average global foreground Dice: [0.9344804436214691, 0.8440223167248879, 0.8573144119088084, 0.4178070603222628, 0.9237976577714139, 0.915026570490245, 0.5330033188952017, 0.4544665658393871, 0.6494216525645111, 0.7350987246459302, 0.13561634791029337, 0.8078442521130447, 0.7631644858444886, 0.0, 0.5326781257875403, 0.8080077318459684] 
2021-04-30 02:52:45.670015: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-30 02:52:46.057659: lr: 0.008058 
2021-04-30 02:52:46.087494: saving checkpoint... 
2021-04-30 02:52:47.144781: done, saving took 1.09 seconds 
2021-04-30 02:52:47.155624: This epoch took 347.135349 s
 
2021-04-30 02:52:47.155860: 
epoch:  64 
2021-04-30 02:58:07.932135: train loss : 0.0037 
2021-04-30 02:58:32.994585: validation loss: 0.0126 
2021-04-30 02:58:32.996144: Average global foreground Dice: [0.9313666253375813, 0.8717393701019707, 0.8785100112634523, 0.3984783199409961, 0.9343875353560455, 0.8803665851408301, 0.5305582554426069, 0.4585165137951726, 0.6368773849536277, 0.7246008247528551, 0.09315849909249176, 0.7233107127840435, 0.7297657397715197, 0.0, 0.5703083918872659, 0.8066544645453748] 
2021-04-30 02:58:32.996388: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-30 02:58:33.385575: lr: 0.008027 
2021-04-30 02:58:33.415433: saving checkpoint... 
2021-04-30 02:58:34.510201: done, saving took 1.12 seconds 
2021-04-30 02:58:34.518062: This epoch took 347.362002 s
 
2021-04-30 02:58:34.518284: 
epoch:  65 
