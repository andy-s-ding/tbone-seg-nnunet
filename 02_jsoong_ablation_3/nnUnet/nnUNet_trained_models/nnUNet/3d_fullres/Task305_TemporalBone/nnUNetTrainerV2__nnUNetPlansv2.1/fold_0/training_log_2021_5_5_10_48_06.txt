Starting... 
2021-05-05 10:48:06.325206: Using splits from existing split file: /media/jpsoong/New Volume/jsad-tbone/02_jsoong_ablation_3/nnUnet/nnUNet_preprocessed/Task305_TemporalBone/splits_final.pkl 
2021-05-05 10:48:06.326288: The split file contains 1 splits. 
2021-05-05 10:48:06.326455: Desired fold for training: 0 
2021-05-05 10:48:06.326616: This split has 120 training and 7 validation cases. 
2021-05-05 10:48:06.493695: TRAINING KEYS:
 odict_keys(['jhu_000', 'jhu_001', 'jhu_002', 'jhu_003', 'jhu_004', 'jhu_012', 'jhu_013', 'jhu_014', 'jhu_015', 'jhu_016', 'jhu_017', 'jhu_018', 'jhu_019', 'jhu_020', 'jhu_021', 'jhu_022', 'jhu_023', 'jhu_024', 'jhu_025', 'jhu_026', 'jhu_027', 'jhu_028', 'jhu_029', 'jhu_030', 'jhu_031', 'jhu_032', 'jhu_033', 'jhu_034', 'jhu_035', 'jhu_036', 'jhu_037', 'jhu_038', 'jhu_039', 'jhu_040', 'jhu_041', 'jhu_042', 'jhu_043', 'jhu_044', 'jhu_045', 'jhu_046', 'jhu_047', 'jhu_048', 'jhu_049', 'jhu_050', 'jhu_051', 'jhu_052', 'jhu_053', 'jhu_054', 'jhu_055', 'jhu_056', 'jhu_057', 'jhu_058', 'jhu_059', 'jhu_060', 'jhu_061', 'jhu_062', 'jhu_063', 'jhu_064', 'jhu_065', 'jhu_066', 'jhu_067', 'jhu_068', 'jhu_069', 'jhu_070', 'jhu_071', 'jhu_072', 'jhu_073', 'jhu_074', 'jhu_075', 'jhu_076', 'jhu_077', 'jhu_078', 'jhu_079', 'jhu_080', 'jhu_081', 'jhu_082', 'jhu_083', 'jhu_084', 'jhu_085', 'jhu_086', 'jhu_087', 'jhu_088', 'jhu_089', 'jhu_090', 'jhu_091', 'jhu_092', 'jhu_093', 'jhu_094', 'jhu_095', 'jhu_096', 'jhu_097', 'jhu_098', 'jhu_099', 'jhu_100', 'jhu_101', 'jhu_102', 'jhu_103', 'jhu_104', 'jhu_105', 'jhu_106', 'jhu_107', 'jhu_108', 'jhu_109', 'jhu_110', 'jhu_111', 'jhu_112', 'jhu_113', 'jhu_114', 'jhu_115', 'jhu_116', 'jhu_117', 'jhu_118', 'jhu_119', 'jhu_120', 'jhu_121', 'jhu_122', 'jhu_123', 'jhu_124', 'jhu_125', 'jhu_126']) 
2021-05-05 10:48:06.494485: VALIDATION KEYS:
 odict_keys(['jhu_005', 'jhu_006', 'jhu_007', 'jhu_008', 'jhu_009', 'jhu_010', 'jhu_011']) 
2021-05-05 10:48:10.336132: loading checkpoint /media/jpsoong/New Volume/jsad-tbone/02_jsoong_ablation_3/nnUnet/nnUNet_trained_models/nnUNet/3d_fullres/Task305_TemporalBone/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0/model_latest.model train= True 
2021-05-05 10:48:10.561831: lr: 0.008487 
2021-05-05 10:48:29.314493: Unable to plot network architecture: 
2021-05-05 10:48:29.353840: No module named 'hiddenlayer' 
2021-05-05 10:48:29.398288: 
printing the network instead:
 
2021-05-05 10:48:29.437275: Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=[2, 2, 2], stride=[2, 2, 2], bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=[2, 2, 2], stride=[2, 2, 2], bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=[2, 2, 2], stride=[2, 2, 2], bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=[2, 2, 2], stride=[2, 2, 2], bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=[2, 2, 2], stride=[2, 2, 2], bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 17, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 17, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 17, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 17, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 17, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
) 
2021-05-05 10:48:29.487300: 
 
2021-05-05 10:48:29.526311: 
epoch:  50 
2021-05-05 10:54:25.047668: train loss : 0.0554 
2021-05-05 10:54:51.499715: validation loss: 0.0770 
2021-05-05 10:54:51.501884: Average global foreground Dice: [0.9447729663308458, 0.8241132482632566, 0.8133395490175765, 0.3575944665467091, 0.9280948502011162, 0.8863362956137164, 0.4391445040897384, 0.4659855469723399, 0.564441781467751, 0.7476483980339673, 0.0, 0.7774560460347303, 0.7171943104781163, 0.0, 0.6456370490369099, 0.6815862816663166] 
2021-05-05 10:54:51.502370: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-05-05 10:54:52.048428: lr: 0.008456 
2021-05-05 10:54:52.077364: saving checkpoint... 
2021-05-05 10:54:53.229264: done, saving took 1.18 seconds 
2021-05-05 10:54:53.235437: This epoch took 383.671840 s
 
2021-05-05 10:54:53.235699: 
epoch:  51 
2021-05-05 11:00:36.428848: train loss : 0.0143 
2021-05-05 11:01:02.935519: validation loss: -0.0122 
2021-05-05 11:01:02.938113: Average global foreground Dice: [0.9483028423030023, 0.8533255872933488, 0.8330354778446164, 0.39478529133701545, 0.9434731593916743, 0.9237507077128208, 0.38942326722875353, 0.41569203827631496, 0.564050429016324, 0.734569501201124, 0.0, 0.8162318420991878, 0.7328599684386875, 0.0, 0.7688037589282214, 0.7809592527991269] 
2021-05-05 11:01:02.938305: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-05-05 11:01:03.342769: lr: 0.008426 
2021-05-05 11:01:03.372617: saving checkpoint... 
2021-05-05 11:01:04.539068: done, saving took 1.20 seconds 
2021-05-05 11:01:04.543615: This epoch took 371.307601 s
 
2021-05-05 11:01:04.543847: 
epoch:  52 
2021-05-05 11:06:48.329505: train loss : 0.0168 
2021-05-05 11:07:14.684020: validation loss: -0.0075 
2021-05-05 11:07:14.686140: Average global foreground Dice: [0.9457620791107176, 0.7993454019561825, 0.8283244750291178, 0.5032168267059547, 0.925644537034347, 0.8814593932078747, 0.32924353769464, 0.37110580272718224, 0.518734713371187, 0.716218360464311, 0.0, 0.8788490280836918, 0.7633421935064859, 0.0, 0.5920772861821534, 0.7759969590100091] 
2021-05-05 11:07:14.686367: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-05-05 11:07:15.079315: lr: 0.008395 
2021-05-05 11:07:15.107641: saving checkpoint... 
2021-05-05 11:07:16.166273: done, saving took 1.09 seconds 
2021-05-05 11:07:16.169266: This epoch took 371.625194 s
 
2021-05-05 11:07:16.169415: 
epoch:  53 
2021-05-05 11:12:59.368664: train loss : 0.0211 
2021-05-05 11:13:25.685546: validation loss: 0.0498 
2021-05-05 11:13:25.687518: Average global foreground Dice: [0.9278218467847157, 0.8184118995661738, 0.8520074893383116, 0.41438525808262605, 0.942544961192375, 0.9198778214764031, 0.4328544560871146, 0.30364131512976356, 0.6117717239081247, 0.7644280010974958, 0.0, 0.7957319022437485, 0.7547040930837778, 0.0, 0.5075269247041031, 0.7700470255761939] 
2021-05-05 11:13:25.687719: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-05-05 11:13:26.053404: lr: 0.008364 
2021-05-05 11:13:26.053736: This epoch took 369.884180 s
 
2021-05-05 11:13:26.053959: 
epoch:  54 
2021-05-05 11:19:08.743961: train loss : -0.0010 
2021-05-05 11:19:35.043247: validation loss: 0.0458 
2021-05-05 11:19:35.045563: Average global foreground Dice: [0.9448794447969654, 0.8707323641966417, 0.8701766041078448, 0.41227857596214873, 0.9092809996049515, 0.8471451566843075, 0.4059055963858167, 0.4121299679108728, 0.574414403100731, 0.696831017378857, 0.0, 0.688729373681041, 0.6793846288424089, 0.0, 0.4476698140178178, 0.8383807339515488] 
2021-05-05 11:19:35.045797: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-05-05 11:19:35.438948: lr: 0.008334 
2021-05-05 11:19:35.439155: This epoch took 369.384980 s
 
2021-05-05 11:19:35.439277: 
epoch:  55 
2021-05-05 11:25:14.894002: train loss : 0.0410 
2021-05-05 11:25:40.957285: validation loss: 0.0085 
2021-05-05 11:25:40.959458: Average global foreground Dice: [0.9557919265988943, 0.8277748937810385, 0.8660058171204226, 0.3324845203313051, 0.9175058124962251, 0.886382655326707, 0.4630988156266572, 0.3501560567693304, 0.6430761006182002, 0.7232478131868457, 0.0, 0.8300571318823684, 0.7361378385828601, 0.0, 0.7371116647542697, 0.8507458483405836] 
2021-05-05 11:25:40.959689: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-05-05 11:25:41.344911: lr: 0.008303 
2021-05-05 11:25:41.370308: saving checkpoint... 
2021-05-05 11:25:42.461738: done, saving took 1.12 seconds 
2021-05-05 11:25:42.466009: This epoch took 367.026612 s
 
2021-05-05 11:25:42.466212: 
epoch:  56 
2021-05-05 11:31:22.357121: train loss : 0.0010 
2021-05-05 11:31:48.546317: validation loss: -0.0577 
2021-05-05 11:31:48.548258: Average global foreground Dice: [0.9445782061094694, 0.842020439037945, 0.8352960925222204, 0.42821321284043795, 0.9316371480797407, 0.9126448224164398, 0.36580838881205074, 0.32131665249605246, 0.6635405798542695, 0.7364155050383244, 0.0, 0.8287948573012868, 0.799986832036766, 0.0, 0.6206078120875331, 0.8021732843858229] 
2021-05-05 11:31:48.548478: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-05-05 11:31:48.986492: lr: 0.008272 
2021-05-05 11:31:49.013970: saving checkpoint... 
2021-05-05 11:31:50.108110: done, saving took 1.12 seconds 
2021-05-05 11:31:50.112753: This epoch took 367.646346 s
 
2021-05-05 11:31:50.112972: 
epoch:  57 
2021-05-05 11:37:29.848024: train loss : 0.0132 
2021-05-05 11:37:55.952932: validation loss: 0.0337 
2021-05-05 11:37:55.954900: Average global foreground Dice: [0.9499354906129465, 0.8648098846747877, 0.8509349681248858, 0.4579145966138094, 0.920806453830096, 0.866606961329491, 0.40734196386715227, 0.4522799993695128, 0.5886072244013817, 0.7358590989802003, 0.0, 0.7920408976677885, 0.7134697379698572, 0.0, 0.6976974146980207, 0.772703808496422] 
2021-05-05 11:37:55.955113: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-05-05 11:37:56.345411: lr: 0.008242 
2021-05-05 11:37:56.375493: saving checkpoint... 
2021-05-05 11:37:57.578044: done, saving took 1.23 seconds 
2021-05-05 11:37:57.588948: This epoch took 367.475773 s
 
2021-05-05 11:37:57.589189: 
epoch:  58 
2021-05-05 11:43:33.974690: train loss : -0.0054 
2021-05-05 11:43:59.201308: validation loss: 0.0807 
2021-05-05 11:43:59.203903: Average global foreground Dice: [0.9403585041014799, 0.8433697751042646, 0.8512314921535598, 0.4591313935914375, 0.9083301933446308, 0.8641033110770043, 0.3934621013432252, 0.2974712864011757, 0.49586018193878517, 0.7355617958520824, 0.0, 0.7471261444753465, 0.6770964754911994, 0.0, 0.4379422291864145, 0.8344600496591205] 
2021-05-05 11:43:59.204093: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-05-05 11:43:59.596520: lr: 0.008211 
2021-05-05 11:43:59.596754: This epoch took 362.007354 s
 
2021-05-05 11:43:59.596885: 
epoch:  59 
2021-05-05 11:49:26.820472: train loss : 0.0096 
2021-05-05 11:49:52.033407: validation loss: 0.0531 
2021-05-05 11:49:52.035688: Average global foreground Dice: [0.9441068901455395, 0.8840644710771485, 0.8718354402251302, 0.42793099677861607, 0.9281977689075359, 0.897507534481717, 0.42718664879588397, 0.43199577827843066, 0.5935789906769247, 0.7112440496037281, 0.0, 0.5971783929600745, 0.6710993692426994, 0.0, 0.6626297631101905, 0.7961395069427781] 
2021-05-05 11:49:52.035860: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-05-05 11:49:52.436695: lr: 0.008181 
2021-05-05 11:49:52.437045: This epoch took 352.840030 s
 
2021-05-05 11:49:52.437301: 
epoch:  60 
2021-05-05 11:55:20.088621: train loss : -0.0237 
2021-05-05 11:55:45.299695: validation loss: -0.0070 
2021-05-05 11:55:45.301340: Average global foreground Dice: [0.9451712154267411, 0.7654385162872837, 0.8047735405732577, 0.4511881853587574, 0.9325964747558217, 0.9105366049427938, 0.30767061477721375, 0.29665846174596217, 0.6709010408215303, 0.7358660825097884, 0.0, 0.7706909195239997, 0.7916772123992757, 0.0, 0.666742037693504, 0.818070626195097] 
2021-05-05 11:55:45.301506: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-05-05 11:55:45.663603: lr: 0.00815 
2021-05-05 11:55:45.663888: This epoch took 353.226337 s
 
2021-05-05 11:55:45.664066: 
epoch:  61 
2021-05-05 12:01:13.054296: train loss : -0.0272 
2021-05-05 12:01:38.292197: validation loss: 0.0191 
2021-05-05 12:01:38.293761: Average global foreground Dice: [0.9520699645109668, 0.8341568202192499, 0.835972099952597, 0.36200530518121593, 0.9226370061466171, 0.8768554774637465, 0.3343198509262304, 0.3929744279946164, 0.6145346181454332, 0.7486348856233528, 0.0038445973290165926, 0.8558370673974117, 0.7326820963320291, 0.0, 0.7603177043794572, 0.7652622394562166] 
2021-05-05 12:01:38.293952: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-05-05 12:01:38.688956: lr: 0.008119 
2021-05-05 12:01:38.689167: This epoch took 353.024936 s
 
2021-05-05 12:01:38.689292: 
epoch:  62 
2021-05-05 12:07:06.208746: train loss : -0.0230 
2021-05-05 12:07:31.432831: validation loss: -0.0155 
2021-05-05 12:07:31.434987: Average global foreground Dice: [0.9464503337840928, 0.8324141863382369, 0.8614022999997827, 0.4875821933338372, 0.9166654042075049, 0.924676373560735, 0.4770671072299583, 0.33512434500540633, 0.5674187970883102, 0.7659424106051352, 0.04132137263277801, 0.7739895955634457, 0.7995712678074749, 0.0, 0.697308062237807, 0.8401443291944141] 
2021-05-05 12:07:31.436277: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-05-05 12:07:31.808707: lr: 0.008088 
2021-05-05 12:07:31.835629: saving checkpoint... 
2021-05-05 12:07:32.999934: done, saving took 1.19 seconds 
2021-05-05 12:07:33.004234: This epoch took 354.314816 s
 
2021-05-05 12:07:33.004434: 
epoch:  63 
2021-05-05 12:13:00.073265: train loss : -0.0537 
2021-05-05 12:13:25.245087: validation loss: 0.0301 
2021-05-05 12:13:25.247165: Average global foreground Dice: [0.9451652967836018, 0.847373227320594, 0.8613879530850334, 0.4873163666459756, 0.9271286821917266, 0.8844506763359893, 0.5380681199898437, 0.3290339940801866, 0.6192663757901213, 0.705782519982339, 0.02790416402695387, 0.7127404137216523, 0.6965490337647525, 0.0, 0.6383703293051828, 0.8318107347744884] 
2021-05-05 12:13:25.247331: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-05-05 12:13:25.635263: lr: 0.008058 
2021-05-05 12:13:25.662969: saving checkpoint... 
2021-05-05 12:13:26.739474: done, saving took 1.10 seconds 
2021-05-05 12:13:26.743972: This epoch took 353.739351 s
 
2021-05-05 12:13:26.744151: 
epoch:  64 
2021-05-05 12:18:53.696517: train loss : -0.0422 
2021-05-05 12:19:18.877479: validation loss: 0.0044 
2021-05-05 12:19:18.879678: Average global foreground Dice: [0.9416424210284727, 0.8525733427174, 0.8569781135137267, 0.4351505717010711, 0.9393945398939156, 0.855315844058368, 0.435616116872259, 0.520322447892711, 0.574472065096722, 0.7573687611212222, 0.17480672615906953, 0.8349600439708055, 0.7442167730177199, 0.0, 0.7186042838339117, 0.8163084094600281] 
2021-05-05 12:19:18.879947: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-05-05 12:19:19.285301: lr: 0.008027 
2021-05-05 12:19:19.312840: saving checkpoint... 
2021-05-05 12:19:20.393026: done, saving took 1.11 seconds 
2021-05-05 12:19:20.398425: This epoch took 353.654110 s
 
2021-05-05 12:19:20.398655: 
epoch:  65 
2021-05-05 12:24:47.569689: train loss : -0.0234 
2021-05-05 12:25:12.668591: validation loss: -0.0658 
2021-05-05 12:25:12.670678: Average global foreground Dice: [0.9462789510105956, 0.8743534440001021, 0.8560713885912588, 0.4957941552522589, 0.9338069324815421, 0.9207215753144075, 0.4606824739681345, 0.288686788394548, 0.6192635203360758, 0.7797494575735467, 0.04200913242009133, 0.8161907853397898, 0.7499438452559367, 0.0, 0.7200613013861512, 0.8216227084602388] 
2021-05-05 12:25:12.670861: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-05-05 12:25:13.069585: lr: 0.007996 
2021-05-05 12:25:13.096663: saving checkpoint... 
2021-05-05 12:25:14.211867: done, saving took 1.14 seconds 
2021-05-05 12:25:14.216602: This epoch took 353.817734 s
 
2021-05-05 12:25:14.216819: 
epoch:  66 
