Starting... 
2021-04-29 19:56:06.181615: Using splits from existing split file: /media/jpsoong/New Volume/jsad-tbone/02_jsoong_ablation_3/nnUnet/nnUNet_preprocessed/Task305_TemporalBone/splits_final.pkl 
2021-04-29 19:56:06.183034: The split file contains 1 splits. 
2021-04-29 19:56:06.183254: Desired fold for training: 0 
2021-04-29 19:56:06.183470: This split has 120 training and 7 validation cases. 
2021-04-29 19:56:06.339312: TRAINING KEYS:
 odict_keys(['jhu_000', 'jhu_001', 'jhu_002', 'jhu_003', 'jhu_004', 'jhu_012', 'jhu_013', 'jhu_014', 'jhu_015', 'jhu_016', 'jhu_017', 'jhu_018', 'jhu_019', 'jhu_020', 'jhu_021', 'jhu_022', 'jhu_023', 'jhu_024', 'jhu_025', 'jhu_026', 'jhu_027', 'jhu_028', 'jhu_029', 'jhu_030', 'jhu_031', 'jhu_032', 'jhu_033', 'jhu_034', 'jhu_035', 'jhu_036', 'jhu_037', 'jhu_038', 'jhu_039', 'jhu_040', 'jhu_041', 'jhu_042', 'jhu_043', 'jhu_044', 'jhu_045', 'jhu_046', 'jhu_047', 'jhu_048', 'jhu_049', 'jhu_050', 'jhu_051', 'jhu_052', 'jhu_053', 'jhu_054', 'jhu_055', 'jhu_056', 'jhu_057', 'jhu_058', 'jhu_059', 'jhu_060', 'jhu_061', 'jhu_062', 'jhu_063', 'jhu_064', 'jhu_065', 'jhu_066', 'jhu_067', 'jhu_068', 'jhu_069', 'jhu_070', 'jhu_071', 'jhu_072', 'jhu_073', 'jhu_074', 'jhu_075', 'jhu_076', 'jhu_077', 'jhu_078', 'jhu_079', 'jhu_080', 'jhu_081', 'jhu_082', 'jhu_083', 'jhu_084', 'jhu_085', 'jhu_086', 'jhu_087', 'jhu_088', 'jhu_089', 'jhu_090', 'jhu_091', 'jhu_092', 'jhu_093', 'jhu_094', 'jhu_095', 'jhu_096', 'jhu_097', 'jhu_098', 'jhu_099', 'jhu_100', 'jhu_101', 'jhu_102', 'jhu_103', 'jhu_104', 'jhu_105', 'jhu_106', 'jhu_107', 'jhu_108', 'jhu_109', 'jhu_110', 'jhu_111', 'jhu_112', 'jhu_113', 'jhu_114', 'jhu_115', 'jhu_116', 'jhu_117', 'jhu_118', 'jhu_119', 'jhu_120', 'jhu_121', 'jhu_122', 'jhu_123', 'jhu_124', 'jhu_125', 'jhu_126']) 
2021-04-29 19:56:06.339726: VALIDATION KEYS:
 odict_keys(['jhu_005', 'jhu_006', 'jhu_007', 'jhu_008', 'jhu_009', 'jhu_010', 'jhu_011']) 
2021-04-29 19:56:10.280768: loading checkpoint /media/jpsoong/New Volume/jsad-tbone/02_jsoong_ablation_3/nnUnet/nnUNet_trained_models/nnUNet/3d_fullres/Task305_TemporalBone/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0/model_latest.model train= True 
2021-04-29 19:56:10.509698: lr: 0.008487 
2021-04-29 19:56:28.302309: Unable to plot network architecture: 
2021-04-29 19:56:28.346111: No module named 'hiddenlayer' 
2021-04-29 19:56:28.391587: 
printing the network instead:
 
2021-04-29 19:56:28.433612: Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1])
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=[2, 2, 2], stride=[2, 2, 2], bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=[2, 2, 2], stride=[2, 2, 2], bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=[2, 2, 2], stride=[2, 2, 2], bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=[2, 2, 2], stride=[2, 2, 2], bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=[2, 2, 2], stride=[2, 2, 2], bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 17, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 17, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 17, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 17, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 17, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
) 
2021-04-29 19:56:28.484447: 
 
2021-04-29 19:56:28.523583: 
epoch:  50 
2021-04-29 20:02:00.187860: train loss : 0.0462 
2021-04-29 20:02:25.238767: validation loss: 0.0273 
2021-04-29 20:02:25.240821: Average global foreground Dice: [0.949049126453728, 0.7713760691161332, 0.7851115254032732, 0.39430904089374363, 0.925925025379154, 0.9016630385166957, 0.32094242820090496, 0.33626301521247387, 0.5918652505289688, 0.74302853493429, 0.0, 0.7594483630126607, 0.7157660731020928, 0.0, 0.65465210857907, 0.8391060026098421] 
2021-04-29 20:02:25.241646: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-29 20:02:25.839057: lr: 0.008456 
2021-04-29 20:02:25.869418: saving checkpoint... 
2021-04-29 20:02:27.047110: done, saving took 1.21 seconds 
2021-04-29 20:02:27.057401: This epoch took 358.496851 s
 
2021-04-29 20:02:27.057666: 
epoch:  51 
2021-04-29 20:07:47.794986: train loss : 0.0594 
2021-04-29 20:08:12.793766: validation loss: 0.0411 
2021-04-29 20:08:12.795795: Average global foreground Dice: [0.9440558620617596, 0.8073001826137515, 0.7759170989875628, 0.42885673680717723, 0.9004720808078177, 0.865289932421687, 0.2715760528727869, 0.27370259750062, 0.560715166461159, 0.677952077823492, 0.0, 0.535315339453944, 0.7207464709792292, 0.0, 0.6829290071480133, 0.8277011285588939] 
2021-04-29 20:08:12.795981: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-29 20:08:13.181011: lr: 0.008426 
2021-04-29 20:08:13.181200: This epoch took 346.123304 s
 
2021-04-29 20:08:13.181341: 
epoch:  52 
2021-04-29 20:13:33.826499: train loss : 0.0409 
2021-04-29 20:13:58.856934: validation loss: -0.0205 
2021-04-29 20:13:58.858855: Average global foreground Dice: [0.9545168574557841, 0.8289078357219093, 0.8241183943225613, 0.35962615583468666, 0.933287578699138, 0.9229441235087203, 0.3803310925390942, 0.2562553434026788, 0.5661441149640536, 0.745998118713492, 0.0, 0.8104535804559989, 0.7536025155315462, 0.0, 0.5843508757266916, 0.7707420407624004] 
2021-04-29 20:13:58.859076: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-29 20:13:59.310736: lr: 0.008395 
2021-04-29 20:13:59.310976: This epoch took 346.129505 s
 
2021-04-29 20:13:59.311139: 
epoch:  53 
2021-04-29 20:19:20.552914: train loss : 0.0104 
2021-04-29 20:19:45.573951: validation loss: 0.0024 
2021-04-29 20:19:45.575937: Average global foreground Dice: [0.9581682949223982, 0.8051242866353064, 0.8000930921163315, 0.3904374811193804, 0.9036334951601461, 0.8832106291337157, 0.4263014688689072, 0.3241677360911905, 0.5843623048476126, 0.705068851728603, 0.0, 0.7780979794549646, 0.7465473495321182, 0.0, 0.7193884401510793, 0.8447064719175678] 
2021-04-29 20:19:45.576126: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-29 20:19:45.962752: lr: 0.008364 
2021-04-29 20:19:45.962952: This epoch took 346.651644 s
 
2021-04-29 20:19:45.963080: 
epoch:  54 
2021-04-29 20:25:06.632265: train loss : 0.0019 
2021-04-29 20:25:31.652192: validation loss: -0.0153 
2021-04-29 20:25:31.654232: Average global foreground Dice: [0.957893861989839, 0.823846461559747, 0.827637159666165, 0.3814693177589749, 0.9198945685911407, 0.9287184163078742, 0.4618072710183523, 0.3687233775280642, 0.7175112388950889, 0.7367698305688707, 0.0, 0.7168500661134461, 0.7190693609710697, 0.0, 0.6389849543337054, 0.8078421533686923] 
2021-04-29 20:25:31.654476: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-29 20:25:32.041173: lr: 0.008334 
2021-04-29 20:25:32.070848: saving checkpoint... 
2021-04-29 20:25:33.139239: done, saving took 1.10 seconds 
2021-04-29 20:25:33.149956: This epoch took 347.186747 s
 
2021-04-29 20:25:33.150150: 
epoch:  55 
2021-04-29 20:30:54.058350: train loss : 0.0320 
2021-04-29 20:31:19.141241: validation loss: 0.1222 
2021-04-29 20:31:19.143194: Average global foreground Dice: [0.9403721555532323, 0.8639876664035128, 0.8382875950545755, 0.3841438340998665, 0.909568526393034, 0.9256945277074562, 0.4421658549700884, 0.21691115872754244, 0.6838102013474282, 0.6962265056422172, 0.0, 0.6043227589612647, 0.6858306763145284, 0.0, 0.4719532394825834, 0.6707915491601165] 
2021-04-29 20:31:19.143389: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-29 20:31:19.521846: lr: 0.008303 
2021-04-29 20:31:19.522091: This epoch took 346.371782 s
 
2021-04-29 20:31:19.522261: 
epoch:  56 
2021-04-29 20:36:40.611863: train loss : 0.0067 
2021-04-29 20:37:05.661731: validation loss: 0.0646 
2021-04-29 20:37:05.663934: Average global foreground Dice: [0.9470916952274777, 0.8024179312680649, 0.8202395323718152, 0.5054168482659859, 0.9257336850576185, 0.8476384305647721, 0.352144958701106, 0.328513276849529, 0.5743041230730038, 0.7099433398919835, 0.0, 0.8280746630804797, 0.6999135524238551, 0.0, 0.5742972921842048, 0.7052695167085917] 
2021-04-29 20:37:05.664237: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-29 20:37:06.051330: lr: 0.008272 
2021-04-29 20:37:06.051555: This epoch took 346.528920 s
 
2021-04-29 20:37:06.051721: 
epoch:  57 
2021-04-29 20:42:26.859476: train loss : 0.0071 
2021-04-29 20:42:51.945442: validation loss: -0.0362 
2021-04-29 20:42:51.949038: Average global foreground Dice: [0.9520416139349163, 0.8700608445367436, 0.8627304657265588, 0.4690874171461585, 0.906851627325773, 0.9282334082397444, 0.4555819988436664, 0.42137128145643843, 0.6060824803951277, 0.7453547541568815, 0.0019519232809284365, 0.6055005943057875, 0.7171722334031658, 0.0, 0.6707797628310758, 0.8403003986648053] 
2021-04-29 20:42:51.949222: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-29 20:42:52.345100: lr: 0.008242 
2021-04-29 20:42:52.345332: This epoch took 346.293453 s
 
2021-04-29 20:42:52.345499: 
epoch:  58 
2021-04-29 20:48:13.664075: train loss : 0.0036 
2021-04-29 20:48:38.751290: validation loss: 0.0446 
2021-04-29 20:48:38.753480: Average global foreground Dice: [0.936620513601803, 0.7756098216475347, 0.7918959189530829, 0.2955273739560779, 0.9102044308400155, 0.9028847112527194, 0.38080873675904786, 0.2662579070025524, 0.6540709992745215, 0.7026899894873756, 0.0041209387064590295, 0.7452160737894481, 0.7252517327150519, 0.0, 0.4560224529359245, 0.8324536725655572] 
2021-04-29 20:48:38.753868: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-29 20:48:39.147100: lr: 0.008211 
2021-04-29 20:48:39.147329: This epoch took 346.801667 s
 
2021-04-29 20:48:39.147494: 
epoch:  59 
2021-04-29 20:54:00.217345: train loss : 0.0393 
2021-04-29 20:54:25.314575: validation loss: 0.0147 
2021-04-29 20:54:25.316997: Average global foreground Dice: [0.9479066795924566, 0.8589616012761594, 0.8319051477657747, 0.4165567379005071, 0.9040441093913442, 0.9060494606275578, 0.4510232144301545, 0.39962478958662606, 0.5710514707179786, 0.7095857377045187, 8.985937008581569e-05, 0.6925545622927983, 0.7157558334392338, 0.0, 0.6956985837271722, 0.77705631997209] 
2021-04-29 20:54:25.317382: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-29 20:54:25.719768: lr: 0.008181 
2021-04-29 20:54:25.720048: This epoch took 346.572389 s
 
2021-04-29 20:54:25.720270: 
epoch:  60 
2021-04-29 20:59:46.810573: train loss : -0.0217 
2021-04-29 21:00:11.861039: validation loss: 0.0224 
2021-04-29 21:00:11.863032: Average global foreground Dice: [0.9487393432774162, 0.7945939682610121, 0.8479685049057301, 0.44926889614472004, 0.9278567697054715, 0.9095388754039518, 0.4719060183440131, 0.30217506631299734, 0.5709756707412003, 0.6674323344678745, 0.0104696290502121, 0.7097710543637769, 0.7681457529999937, 0.0, 0.5530302671232056, 0.7722512061768212] 
2021-04-29 21:00:11.863357: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-29 21:00:12.249891: lr: 0.00815 
2021-04-29 21:00:12.250126: This epoch took 346.529634 s
 
2021-04-29 21:00:12.250301: 
epoch:  61 
2021-04-29 21:05:33.147165: train loss : -0.0076 
2021-04-29 21:05:58.363550: validation loss: -0.0118 
2021-04-29 21:05:58.365698: Average global foreground Dice: [0.9459632061296342, 0.8116062314067242, 0.8383288574878792, 0.49131858041090415, 0.919586900621081, 0.9085885577662975, 0.38449190007646694, 0.2158987480895056, 0.49921345051841237, 0.7356702878261844, 0.023953526574376896, 0.7671409565698365, 0.7498966465170549, 0.0, 0.6610723839871993, 0.8260361505342528] 
2021-04-29 21:05:58.366290: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-29 21:05:58.810159: lr: 0.008119 
2021-04-29 21:05:58.810390: This epoch took 346.559918 s
 
2021-04-29 21:05:58.810555: 
epoch:  62 
2021-04-29 21:11:19.774695: train loss : -0.0225 
2021-04-29 21:11:44.811862: validation loss: 0.0125 
2021-04-29 21:11:44.814975: Average global foreground Dice: [0.9325625983858182, 0.8211484355274968, 0.7974250307551664, 0.45956765412329864, 0.9364395525004515, 0.8606864147094515, 0.41926708981135413, 0.29374411259489114, 0.5896540069314196, 0.7762580954404082, 0.18984739704110254, 0.8706326436187435, 0.6592280350114158, 0.0, 0.7436243285801613, 0.8561732947700414] 
2021-04-29 21:11:44.815186: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-29 21:11:45.235404: lr: 0.008088 
2021-04-29 21:11:45.256268: saving checkpoint... 
2021-04-29 21:11:46.352021: done, saving took 1.12 seconds 
2021-04-29 21:11:46.355286: This epoch took 347.544563 s
 
2021-04-29 21:11:46.355504: 
epoch:  63 
2021-04-29 21:17:07.915195: train loss : -0.0149 
2021-04-29 21:17:32.961197: validation loss: -0.0441 
2021-04-29 21:17:32.963197: Average global foreground Dice: [0.9396096515953618, 0.8621656699794117, 0.8629783574602264, 0.4430445340838659, 0.931509817265728, 0.9096696238984748, 0.3557572685803806, 0.28075629948302666, 0.5271086455443997, 0.7819164489954128, 0.04203262233375157, 0.8580409897754253, 0.7572150795037581, 0.0, 0.7538001735385802, 0.8265784798453355] 
2021-04-29 21:17:32.963428: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2021-04-29 21:17:33.341787: lr: 0.008058 
2021-04-29 21:17:33.362643: saving checkpoint... 
2021-04-29 21:17:34.469163: done, saving took 1.13 seconds 
2021-04-29 21:17:34.473914: This epoch took 348.118208 s
 
2021-04-29 21:17:34.474070: 
epoch:  64 
